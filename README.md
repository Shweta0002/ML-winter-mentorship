# Machine Learning Mentorship

This is the repository that contains all the material/code required to get started with the mentorship programme. A few points of administration:

1. The length of the mentorship is around 5 weeks.

2. We assume you have some prior knowledge of programming.

3. For any help with the course, you can contact your mentor. A better option would be to open an issue on this repository, so that others can see your question, and it'll prevent any replicated effort on the part of the mentor.

4. All your code will be pushed to GitHub, so if you haven't already, create a GitHub account. Fork and clone this repository and create your respective folders (refer the sample folder with my name).

5. Create a README.md in your folder where you can keep track of your progress over the next month. The mentors will be using the README.md as a progress tracker. (Refer the sample README.md given)

Don't be afraid to ask any questions (however irrelevant you think it may be). The mentors are here to help you every step of the way.

## Prerequisites:-

1. Language: We'll be using Python3 throughout this course. So familiarise yourself with the language. Also learn to install packages using pip.
2. Python 3 installation : [Download and Install](https://www.python.org/downloads/)
3. Working with Jupyter: [Download and Install](https://jupyter.org/install)
4. git: You'll be using GitHub for all your code/assignment submission, so learn the basics of git: pull, push, add, commit.

 
## Course Structure

### WEEK 1


1. Basics of Python:

    a. Python Fundamentals
    
    b. Variables
    
    c. Data Types
    
    d. Operators
    
    e. Conditions and Loops,
    
    f. Python Functions,
    
    g. Python Data Structures :
         
      - Lists
      
      - Sets
      
      - Tuples
      
      - Strings
      
      - Dictionary

#### Task : Submit atleast 40 problems including Hackerrank and CodeChef within 4 days


### WEEK 2
 
 1. [NumPy](https://numpy.org/):Used for matrix computations.
 
     a. NumPy basics
     
     b. Random Generators 
     
     c. Stastical Computation 
     
     d. Linear algebra - matrices 
     
     e. Norms of Vectors 
     
 2. [Pandas](https://pandas.pydata.org/): Used for data analysis.
 Pandas Basics
 
 3. [Matplotlib](https://matplotlib.org/): Used for data visualization
 
     a. Line plots  
     
     b. Scatter plots 
     
     c.Bar graphs  
     
     d.Normal Distribution
     
 ### Task : Numpy,Pandas Exercise practices
 
 
  ### WEEK 3
  ### [Introduction to Machine learning](https://towardsdatascience.com/machine-learning-an-introduction-23b84d51e6d0)
  ### [Introduction to Supervised and Unsupervised Learning](https://medium.com/@saahil1292/machine-learning-101-supervised-vs-unsupervised-41312b504053)
  ### [Linear regression](https://towardsdatascience.com/linear-regression-detailed-view-ea73175f6e86)
  
   1. Gradient Descent 
   2. Update rule for squared error
   
  ### [Multivariate Regression](https://www.youtube.com/watch?v=J_LnPL3Qg70) : 
  
   1. Boston Housing Prices  
   2. Maximum likelihood estimation 
   3. K-fold cross validation 
  
   ### Task : 
   Submit your code in the Task 3 folder. 

   [Air Quality Prediction](https://www.kaggle.com/chiranjeevbit/air-quality-prediction)
 
   
 ## WEEK 4
 
   ### [Introduction to Logistic Regression](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc)
  1. Likelihood estimation and loss 
  2. [Gradient Descent Update Rule](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc)
  
  ### K-Nearest Neighbours : 
 https://medium.com/datadriveninvestor/k-nearest-neighbors-knn-7b4bd0128da7
  1. Introduction 
  2. Implementation using MNIST Handwritten Digits 
  
  
 ### Task : 
 [Diabetes Prediction](https://www.kaggle.com/uciml/pima-indians-diabetes-database/data)

4.1 Using Logistic Regression

4.2 Using KNN
  
  
 ## WEEK 5
 
 
Introduction to K-Means Clustering

1. [Article/Blog](https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1)

2. [Article](https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-k-means-clustering/) (A bit long but quite useful)
 
Support Vector Machine

1. [Article](https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72)

2. [Code](analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/)

3. [Lecture](https://www.youtube.com/watch?v=TtKF996oEl8)
 
 ### Task : Extracting Dominant Colours
 
 
  
  
  
   
  


   
   
